{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install pypandoc\n","!pip install transformers\n","!pip install docx2txt\n","!pip install python-docx \n","import nltk\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fod94roX0jWM","executionInfo":{"status":"ok","timestamp":1681190063222,"user_tz":240,"elapsed":21142,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"15e681d3-95cc-42cf-a77b-97955b786b6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pypandoc in /usr/local/lib/python3.9/dist-packages (1.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: docx2txt in /usr/local/lib/python3.9/dist-packages (0.8)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (0.8.11)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from python-docx) (4.9.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["!pip install python-docx\n","!pip install lxml==4.9.1"],"metadata":{"id":"qSH9AL5eLuym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681190076863,"user_tz":240,"elapsed":13647,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"126d00bd-89e7-4ff1-c7f3-e585468ee702"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (0.8.11)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from python-docx) (4.9.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lxml==4.9.1 in /usr/local/lib/python3.9/dist-packages (4.9.1)\n"]}]},{"cell_type":"code","source":["!pip install bayoo-docx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BX0xk_WnRlo9","executionInfo":{"status":"ok","timestamp":1681190082692,"user_tz":240,"elapsed":5835,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"3731c7c2-9200-4387-8c5e-4827c86ccbe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bayoo-docx in /usr/local/lib/python3.9/dist-packages (0.2.20)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from bayoo-docx) (4.9.1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FADoDPV0bqt"},"outputs":[],"source":["# Required import\n","import nltk\n","from nltk.corpus import wordnet\n","\n","import docx2txt\n","import spacy\n","import re\n","from docx import Document\n","\n","from docx.shared import RGBColor\n","from docx.oxml import OxmlElement\n","from docx.oxml.ns import qn\n","\n","import docx\n","from docx.enum.text import WD_COLOR_INDEX\n","import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pypandoc\n","import plotly.figure_factory as ff\n","import seaborn as sns\n","import tensorflow\n","from nltk.corpus import stopwords\n","from plotly.offline import iplot\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.layers import Dense, Dropout, Input\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from transformers import BertConfig, BertTokenizerFast, TFBertModel"]},{"cell_type":"code","source":["! pip show lxml"],"metadata":{"id":"ZCG5cC3uNyG4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681190088214,"user_tz":240,"elapsed":5529,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"f5f4fed6-e225-4783-b6b1-756a4b7879f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: lxml\n","Version: 4.9.1\n","Summary: Powerful and Pythonic XML processing library combining libxml2/libxslt with the ElementTree API.\n","Home-page: https://lxml.de/\n","Author: lxml dev team\n","Author-email: lxml-dev@lxml.de\n","License: BSD\n","Location: /usr/local/lib/python3.9/dist-packages\n","Requires: \n","Required-by: bayoo-docx, nbconvert, pandas-datareader, python-docx, yfinance\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPzf_PFi0bqu"},"outputs":[],"source":["start_time = time.time()"]},{"cell_type":"markdown","metadata":{"id":"RW8yp0gW0bqv"},"source":["Find Synonyms of words in dealbreaker words list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5g9OAG7B0bqw"},"outputs":[],"source":["# create function to find synonyms from the dealbreaker words list\n","\n","def get_synonyms(word):\n","    synonyms = []\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            synonyms.append(lemma.name())\n","    return synonyms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1WlZaVZ0bqw"},"outputs":[],"source":["# Already existed words in Parties \n","\n","Parties = [\"Unilateral\", \"One-Way\", \"One Way\", \"company (\\\"Disclosing Party\\\")\", \"company (\\\"Discloser\\\")\", \"corporation (\\\"Disclosing Party\\\")\", \"corporation (\\\"Discloser\\\")\",  \"LLC (\\\"Disclosing Party\\\")\", \"LLC (\\\"Discloser\\\")\",  \"Inc. (\\\"Disclosing Party\\\")\", \"Inc. (\\\"Discloser\\\")\",  \"Incorporated (\\\"Disclosing Party\\\")\", \"Incorporated (\\\"Discloser\\\")\", \"Co. (\\\"Disclosing Party\\\")\", \"Co. (\\\"Discloser\\\")\"]\n","\n","# No change because these words really do not have synonyms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj50z3nC0bqx"},"outputs":[],"source":["# Already existed words in Residuals/ Memories\n","\n","Residuals = [\"residual\", \"residuals\", \"memories\", \"unaided\", \"memory\"]\n","\n","# find synonyms\n","synonyms_residuals = []\n","for word in Residuals:\n","    synonyms_residuals.append(get_synonyms(word))\n","\n","## synonyms_residuals\n","\n","# since each word in Residuals will generate a list of its synonyms,\n","# # hence, combine these sublists into one list\n","combined_synonyms_residuals = []\n","for sublst in synonyms_residuals:\n","    combined_synonyms_residuals.extend(sublst)\n","\n","# clean the list to only pick up unique words, since some words' synonyms may be repeated\n","unique_synonyms_residuals = list(set(combined_synonyms_residuals))\n","\n","\n","# Notice: \n","# There are TWO lists of words of Residuals now:\n","# Only is only about Residuals Dealbreaker words\n","# Second one is about synonyms of Residuals Dealbreaker words.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74n7-tvA0bqx"},"outputs":[],"source":["# Arealdy existed words in Limitation of Liability\n","\n","Limitation = [\"Limitation of Liability\", \"under no circumstances\", \"shall be limited\", \"special, incidental, indirect or consequential damages\", \"punitive\",\"exemplary\",\"consequential\",\"indirect\",\"incidental\"]\n","words_in_limitation = [\"punitive\",\"exemplary\",\"consequential\",\"indirect\",\"incidental\"]\n","\n","# find synonyms\n","synonyms_limitation = []\n","for word in words_in_limitation:\n","    synonyms_limitation.append(get_synonyms(word))\n","\n","## synonyms_limitation\n","\n","# combined sublists into one list\n","combined_synonyms_limitation = []\n","for sublst in synonyms_limitation:\n","    combined_synonyms_limitation.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_limitation = list(set(combined_synonyms_limitation))\n","\n","# Notice: \n","# There are TWO lists of words of Limitation of Liability now:\n","# Only is only about Limitation of Liability Dealbreaker words\n","# Second one is about synonyms of Limitation of Liability Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7ZaVkPX0bqy"},"outputs":[],"source":["# Already existed words in Non-competition\n","\n","Noncompetition = [\"compete\", \"competition\", \"non-compete\", \"non-competition\", \"non compete\", \"non competition\" ]\n","\n","# find synonyms\n","synonyms_noncompetition = []\n","for word in Noncompetition:\n","    synonyms_noncompetition.append(get_synonyms(word))\n","\n","## synonyms_noncompetition\n","\n","# combined sublists into one list\n","combined_synonyms_noncompetition = []\n","for sublst in synonyms_noncompetition:\n","    combined_synonyms_noncompetition.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_noncompetition = list(set(combined_synonyms_noncompetition))\n","\n","\n","\n","# Notice: \n","# There are TWO lists of words of Noncompetition now:\n","# Only is only about Residuals Noncompetition words\n","# Second one is about synonyms of Noncompetition Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNKwKuzd0bqz"},"outputs":[],"source":["# Already existed words in Non-solicitation\n","\n","Nonsolicitation = [\"non-solicitation\", \"solicit\", \"non-solicit\", \"non-servicing\",   \"nonsolicitation\", \"nonsolicit\", \"nonservicing\",  \"solicit\",  \"non solicitation\", \"non solicit\", \"non servicing\",  \"no solicit\", \"no-solicit\"]\n","\n","# find synonyms\n","synonyms_nonsolicitation = []\n","for word in Nonsolicitation:\n","    synonyms_nonsolicitation.append(get_synonyms(word))\n","\n","## synonyms_nonsolicitation\n","\n","# combined sublists into one list\n","combined_synonyms_nonsolicitation = []\n","for sublst in synonyms_nonsolicitation:\n","    combined_synonyms_nonsolicitation.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_nonsolicitation = list(set(combined_synonyms_nonsolicitation))\n","\n","\n","# Notice: \n","# There are TWO lists of words of Nonsolicitation now:\n","# Only is only about Residuals Dealbreaker words\n","# Second one is about synonyms of Residuals Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcD8zE_30bqz"},"outputs":[],"source":["# Already existed words in Indemnification\n","\n","Indemnification = [\"indemnification\", \"indemnity\", \"hold-harmless\", \"hold harmless\", \"indemnify\", \"indemnified\", \"indemnifying\", \"defend\"]\n","\n","# find synonyms\n","synonyms_indemnification = []\n","for word in Indemnification:\n","    synonyms_indemnification.append(get_synonyms(word))\n","\n","## synonyms_indemnification\n","\n","# combined sublists into one list\n","combined_synonyms_indemnification = []\n","for sublst in synonyms_indemnification:\n","    combined_synonyms_indemnification.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_indemnification = list(set(combined_synonyms_indemnification))\n","\n","# Notice: \n","# There are TWO lists of words of Indemnification now:\n","# Only is only about Indemnification Dealbreaker words\n","# Second one is about synonyms of Indemnification Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lM1oSQSZ0bqz"},"outputs":[],"source":["# Already existed words in Governing Law/ Jurisdiction\n","\n","# No change, these words are only country names.\n","\n","Governing = [\"Texas\", \"Italy\", \"Italian\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_h4ujHK0bq0"},"outputs":[],"source":["# Already existed words in Exceptions\n","\n","# No changes, they are not words but lines.\n","Exceptions =  [\"was communicated by Disclosing Party to an unaffiliated third party free of any obligation of confidence\",   \"was communicated by Disclosing Party to a third party free of any obligation of confidence\", \"was communicated by Disclosing Party to  a third party without an obligation of confidence\", \"was disclosed by Disclosing Party to  a third party without an obligation of confidence\", \" was disclosed by Discloser to a third party without an obligation of confidentiality\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kD109qy0bq0"},"outputs":[],"source":["# Already existed words for Representatives\n","\n","# Different from the above, this part is for existence, if exist, yes, if not exist, output a warning sign about \"Missing Representatives\"\n","\n","Representatives = [\"responsible\", \"liable\"]\n","\n","# find synonyms\n","synonyms_representatives = []\n","for word in Representatives:\n","    synonyms_representatives.append(get_synonyms(word))\n","\n","## synonyms_representatives\n","\n","# combined sublists into one list\n","combined_synonyms_representatives = []\n","for sublst in synonyms_representatives:\n","    combined_synonyms_representatives.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_representatives = list(set(combined_synonyms_representatives))\n","\n","\n","# Notice: \n","# There are TWO lists of words of Representatives now:\n","# Only is only about Representatives Dealbreaker words\n","# Second one is about synonyms of Representatives Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYUJUuza0bq0"},"outputs":[],"source":["# Already existed words for Remedies\n","\n","# Same as the last one, this part is for existence, if exist, yes, if not exist, output a warning sign about \"Missing Remedies\"\n","Remedies = [\"injunction\", \"injunctive\",\"equitable\"]\n","\n","# find synonyms\n","synonyms_remedies = []\n","for word in Remedies:\n","    synonyms_remedies.append(get_synonyms(word))\n","\n","## synonyms_remedies\n","\n","# combined sublists into one list\n","combined_synonyms_remedies = []\n","for sublst in synonyms_remedies:\n","    combined_synonyms_remedies.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_remedies = list(set(combined_synonyms_remedies))\n","\n","\n","# Notice: \n","# There are TWO lists of words of Remedies now:\n","# Only is only about Remedies Dealbreaker words\n","# Second one is about synonyms of Remedies Dealbreaker words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDpDCmeu0bq0"},"outputs":[],"source":["# Already existed words for Privacy / Personal Information\n","Privacy = [\"Personal Data\", \"Personal Information\",\"PII\", \"GDPR\", \"CCPA\", \"CPRA\", \"Privacy\"]\n","words_in_privacy = [\"Privacy\"]\n","\n","# find synonyms\n","synonyms_privacy = []\n","for word in words_in_privacy:\n","    synonyms_privacy.append(get_synonyms(word))\n","\n","## synonyms_privacy\n","\n","# combined sublists into one list\n","combined_synonyms_privacy = []\n","for sublst in synonyms_privacy:\n","    combined_synonyms_privacy.extend(sublst)\n","\n","# unique words, some have repeated words\n","unique_synonyms_privacy = list(set(combined_synonyms_privacy))\n","\n","# Notice: \n","# There are TWO lists of words of Privacy now:\n","# Only is only about Privacy Dealbreaker words\n","# Second one is about synonyms of Privacy Dealbreaker words.\n"]},{"cell_type":"markdown","metadata":{"id":"14NDf6yN0bq1"},"source":["Test Trials"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IPo_NH_20bq1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681190123904,"user_tz":240,"elapsed":35521,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"da09bf2f-d44b-42a5-c5f5-636d47f2e5a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","1/1 [==============================] - 5s 5s/step\n"]}],"source":["# Test 3\n","\n","##           ###           ##  EEEEEEEEEEEEEEEE      III\n"," ##         ## ##         ##   E                     III\n","  ##       ##   ##       ##    E                     III\n","   ##     ##     ##     ##     EEEEEEEEEEEEEEE       III\n","    ##   ##       ##   ##      E                     III\n","     ## ##         ## ##       E                     III\n","      ##            ##         EEEEEEEEEEEEEEEE      III\n","def ssp():\n","    \n","    # Recreate the exact same model, including its weights and the optimizer\n","    bert_model = tensorflow.keras.models.load_model('/content/drive/MyDrive/Final_pipeline/my_model.h5')\n","\n","    # # Show the model architecture\n","    # bert_model.summary()\n","    import spacy\n","    import re\n","    import nltk\n","    #en_core_web_sm: this package must be the newest version, currently 3.5.0   (by 2023.04.02)\n","    !pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz --quiet\n","    import en_core_web_sm\n","    #open text file in read mode\n","    docxFilename = \"/content/drive/MyDrive/Final_pipeline/NDA.docx\"\n","    output = pypandoc.convert_file([docxFilename], 'plain', outputfile=\"/content/drive/MyDrive/Final_pipeline/text_file.txt\")\n","    text_file = open(\"/content/drive/MyDrive/Final_pipeline/NDA.txt\", \"r\")\n","    \n","    #read whole file to a string\n","    data = text_file.read()\n","\n","    #close file\n","    text_file.close()\n","    #def a function which can split the doc into sentences\n","    def sentence_split(data):\n","        # nlp = spacy.load(\"en_core_web_sm\")\n","        nlp = en_core_web_sm.load()\n","        \n","        #take unicode string  \n","        sentences = nlp(data)\n","\n","\n","        sentencess = list(sentences.sents)\n","\n","        separated_sentences = []\n","\n","        for i in range(len(sentencess)):\n","            sentence = sentencess[i].text\n","            #sentence_separation = re.split('\\t|\\n|\\n\\t', sentence)\n","            sentence = sentence.replace('\\n', '')\n","            sentence = sentence.replace('\\t', '')\n","            sentence = sentence.replace('\\ufeff', '')\n","            sentence = sentence.replace('  ', '')\n","            sentence = sentence.replace('   ', '') #there are always multiple spaces, change them to single space universally\n","            sentences = re.split(r'\\.(?=\\s|$)', sentence)\n","            separated_sentences += sentences\n","\n","\n","        final_separated_sentences = [x for x in separated_sentences if x != '']\n","        return final_separated_sentences\n","\n","\n","    splitted = sentence_split(data)\n","\n","    #now define a function seperating the document into list of paragraphs\n","\n","    def par(splitted):\n","        ind = 0\n","        paragraphs = []\n","        splitting_index = []\n","\n","        #get the index of splitting\n","        for i in range(len(splitted)):\n","            if len(splitted[i].split()) < 5:\n","                splitting_index.append(i)\n","        \n","        for j in range(len(splitting_index)):\n","            temp_para = \"\"\n","            while ind < splitting_index[j]:\n","                temp_para += splitted[ind]\n","                ind += 1\n","            paragraphs.append(temp_para)\n","        return [p for p in paragraphs if len(p.split()) > 5]\n","\n","    paragraphs = par(splitted)\n","    #paragraphs\n","\n","    # Name of the BERT model to use\n","    model_name = 'bert-base-uncased'\n","\n","    # Max length of tokens\n","    max_length = 100\n","\n","    # Load transformers config and set output_hidden_states to False\n","    config = BertConfig.from_pretrained(model_name)\n","    config.output_hidden_states = False\n","\n","    # Load BERT tokenizer\n","    tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n","\n","\n","    test_x = tokenizer(\n","        text=par(splitted),\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        truncation=True,\n","        padding=True, \n","        return_tensors='tf',\n","        return_token_type_ids = False,\n","        return_attention_mask = False,\n","        verbose = True)\n","\n","    #test_x\n","    #predict the possible value \n","    bert_result = bert_model.predict(test_x['input_ids'])\n","    #define a function, which can return the top 3 potential categories of a paragraph\n","    #this method would return a dictionary: key is each paragraph, the corresponding values a the top 3 potential categories\n","    target_names = ['DEF', 'EXP', 'GOV', 'REM', 'RIG', 'TER', 'WAR']\n","\n","    def par_cat(bert_result, paragraphs, target_names, topN):\n","        result = {}\n","        for i in range(len(bert_result[\"CAT\"])):\n","            val = np.argsort(bert_result[\"CAT\"][i])[::-1][:topN]\n","            result[paragraphs[i]] = [target_names[v] for v in val]\n","        return result\n","\n","    return par_cat(bert_result, paragraphs, target_names, 3)\n","#这个名字别改昂\n","\n","\n","original_input_dictionary = ssp()\n","\n","# {'Mutual Nondisclosure AgreementThis Mutual Nondisclosure Agreement (\"Agreement\") is made between Brex Inc': ['RIG','DEF','EXP'],\n","#  ' (\"Company\")The parties may disclose confidential information as part of a potential business relationship or transaction of mutual interest (\"Transaction\") and agree to protect and maintain secrecy of the information disclosed in confidence for the TransactionThe parties agree as follows:1': ['RIG','DEF','EXP'],\n","#  'DefinitionsIn this Agreement: \"Affiliate\" means an entity that is directly or indirectly controls, is controlled by, or is under common control as a party, which shall include the power to direct or cause the direction of the management and policies of a person or an organization, whether by ownership of stock, voting rights, by contract, or otherwise; and \"Confidential Information\" is information disclosed by a party or its Affiliates or agents (collectively, the \"Disclosing Party\") to the other party or its Affiliates or agents (collectively, the \"Receiving Party\") that (a) the Disclosing Party identifies as confidential or proprietary, or (b) reasonably appears to be confidential or proprietary because of legends or other markings, the circumstances of disclosure, or the nature of the information itself, whether or not such information is related to TransactionWithout limiting the foregoing, Confidential Information includes the Disclosing Party’s technology, data, customer information, and business plans; and the details and nature of the Transaction': ['DEF','EXP','RIG'],\n","#  'NondisclosureExcept as expressly permitted in this Agreement, the Receiving Party agrees to hold Confidential Information in strict confidence, only use Confidential Information for the purposes of the Transaction, and not disclose such Confidential Information to any third party except as expressly permitted by this AgreementThe Receiving Party may disclose Confidential Information to its employees or contractors (collectively, the \"Representatives\") with a bona fide need to know but only to the extent necessary under the Transaction provided that each such employee or contractor is bound by confidentiality obligations at least as protective as this AgreementThe Receiving Party will protect Confidential Information with at least the same degree of care that it uses to protect its own confidential or sensitive information but not less than reasonable careThe Receiving Party shall be responsible for any breach of this Agreement by its RepresentativesThe Receiving Party will immediately notify the Disclosing Party upon discovery of any loss or unauthorized disclosure of the Confidential Information of the Disclosing Party': ['RIG','EXP','DEF'],\n","#  'Exclusions and ExceptionsConfidential Information does not include information that is or becomes generally known or available to the public through no act or failure to act on the part of the Receiving Party, was or is legally obtained or learned by the Receiving Party, was legally furnished by a third________________party without restriction of use, or is independently developed by the Receiving Party without use of or reference to Confidential InformationThe Receiving Party may disclose Confidential Information to the extent that disclosure is required by law or court order provided that the Receiving Party uses reasonable efforts to give the Disclosing Party prior notice if such prior notice is permitted by law': ['EXP','DEF','RIG'],\n","#  ' Return or DestructionUpon the Disclosing Party’s request and option, the Receiving Party will promptly return or certify the destruction or deletion of Confidential Information and copies madeNotwithstanding the foregoing, the Receiving Party may keep a copy of Confidential Information: (i) as strictly required by applicable laws, regulations, or internal compliance or recordkeeping policies; and/or (ii) that is kept in archival backup files; provided, however, that any such retained Confidential Information shall remain subject to the terms of this Agreement': ['TER','WAR', 'REM'],\n","#  'No License or WarrantyConfidential Information is and shall remain owned by the Disclosing Party or its licensorsThis Agreement does not grant any express or implied right to the Receiving Party, by license or otherwise, to Confidential InformationConfidential information is provided without any warranties': ['WAR','EXP','DEF'],\n","#  'Injunctive ReliefThe parties acknowledge that unauthorized disclosure or use of Confidential Information may cause irreparable harm to the Disclosing Party that may be difficult to ascertain and for which money damages would be insufficientAccordingly, the Disclosing Party has the right to seek an immediate injunction to mitigate or prevent harm caused by a breach of this Agreement, in addition to the right to pursue other remedies available at law or in equity for such a breach': ['REM','GOV','WAR'],\n","#  'Governing LawThis Agreement is interpreted and governed by the laws of the State of Utah without giving effect to its conflict of law principlesAny legal action or proceeding arising out of or relating to this Agreement may be instituted in the courts of the State of Utah sitting in Salt Lake County, Utah, and the parties hereto irrevocably submit to the jurisdiction of each such court in any action or proceeding': ['GOV','EXP','RIG'],\n","#  'SeverabilityAny provision of this Agreement that is found to be unenforceable will be severed and the remaining terms will be enforced without invalidating the remainder of either the affected provision or this Agreement': ['EXP','TER','REM'],\n","#  'Complete AgreementThis Agreement is the complete and exclusive statement regarding handling and protection of________________ConfidentialInformationandsupersedesallprior understandings and communications, whether oral or written': ['RIG','EXP','DEF'],\n","#  'TermThis Agreement will remain in effect for one (1) year from the Effective Date, at which time it will terminate; provided, however, that the Receiving Party’s confidentiality obligations as provided hereunder will survive termination for an additional two (2) yearsThis Agreement is accepted and agreed as of August 3, 2022': ['TER','EXP','RIG']}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttrNB-h70bq1"},"outputs":[],"source":["paragraphs = list(original_input_dictionary.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7l9prFGc0bq2"},"outputs":[],"source":["# Segment paragraph into sentences. \n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","sentences_in_paragraphs = []  \n","\n","# take unicode string  \n","for i in range(len(paragraphs)):\n","    sentences_in_paragraph = nlp(paragraphs[i])\n","\n","    sentencess = list(sentences_in_paragraph.sents)\n","\n","    separated_sentences = []\n","    # list all sentences\n","    for j in range(len(sentencess)):\n","        sentence = sentencess[j].text\n","    \n","    \n","        sentence = sentence.replace('\\n\\n', ' ')\n","        sentences = re.split(r'\\.(?=\\s|$)', sentence)\n","\n","\n","        separated_sentences += sentences\n","\n","    final_separated_sentences = [x for x in separated_sentences if x != '']\n","\n","    sentences_in_paragraphs.append(final_separated_sentences)\n","\n","## sentences_in_paragraphs"]},{"cell_type":"markdown","metadata":{"id":"uKeTxw9u0bq2"},"source":["Create dictionary for dealbreaker catergories and words with each category"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0Sk4c3o0bq2"},"outputs":[],"source":["# Recall in previous section, we have already find synonyms of dealbreaker words and list them. \n","\n","## Parties\n","## unique_synonyms_residuals\n","## unique_synonyms_limitation\n","## unique_synonyms_noncompetition\n","## unique_synonyms_nonsolicitation\n","## unique_synonyms_indemnification\n","## Governing\n","## Exceptions\n","## unique_synonyms_representatives\n","## unique_synonyms_remedies\n","## unique_synonyms_privacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZ08JF560bq2"},"outputs":[],"source":["# create a dictionary of sensitive words, grouped them by different categories. \n","\n","dealbreaker_words = {\n","    \"Parties\":Parties,\n","     \"Residuals/Memories\": Residuals,\n","     \"Limitation of Liability\": Limitation,\n","     \"Non-competition\": Noncompetition,\n","     \"Non-solicitation\":Nonsolicitation,\n","     \"Indemnification\": Indemnification,\n","     \"Governing Law/Jurisdiction\":Governing,\n","     \"Exceptions\":Exceptions,\n","     \"Privacy\": Privacy\n","}\n","\n","# The reason why not including remedies and representatives is due to the reason that\n","# their search methods are for existence (recall if they exist, then everything is ok, but if not exist, Warning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XZ7HOiZ0bq2"},"outputs":[],"source":["# create a dictionary of synonyms of sensitive words, grouped them by different categories. \n","\n","synonyms_dealbreaker_words = {\n","     \"Synonyms of Residuals/Memories\": unique_synonyms_residuals,\n","     \"Synonyms of Limitation of Liability\": unique_synonyms_limitation,\n","     \"Synonyms of Non-competition\": unique_synonyms_noncompetition,\n","     \"Synonyms of Non-solicitation\":unique_synonyms_nonsolicitation,\n","     \"Synonyms of Indemnification\": unique_synonyms_indemnification,\n","     \"Synonyms of Privacy\": unique_synonyms_privacy\n","}\n","\n","# The reason why not including remedies and representatives is due to the reason that\n","# their search methods are for existence (recall if they exist, then everything is ok, but if not exist, Warning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ld2VUYnX0bq3"},"outputs":[],"source":["update_dealbreaker_words = {\n","    \"DEF\": Parties ,\n","    \"RIG\": Limitation,\n","    \"EXP\": Exceptions,\n","    \"WAR\": Parties + Residuals + Limitation + Noncompetition + Nonsolicitation + Indemnification + Governing + Exceptions + Privacy,\n","    \"GOV\": Governing,\n","    \"REM\": \"1\",\n","    \"TER\": Parties + Residuals + Limitation + Noncompetition + Nonsolicitation + Indemnification + Governing + Exceptions + Privacy\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_uNN3Mg0bq3"},"outputs":[],"source":["update_synonyms_dealbreaker_words = {\n","    \"RIG\": unique_synonyms_limitation,\n","    \"WAR\": unique_synonyms_residuals + unique_synonyms_limitation + unique_synonyms_noncompetition + unique_synonyms_nonsolicitation + unique_synonyms_indemnification  + unique_synonyms_privacy,\n","    \"REM\": \"2\",\n","    \"TER\": unique_synonyms_residuals + unique_synonyms_limitation + unique_synonyms_noncompetition + unique_synonyms_nonsolicitation + unique_synonyms_indemnification  + unique_synonyms_privacy\n","}"]},{"cell_type":"markdown","metadata":{"id":"KqmUpvcB0bq3"},"source":["Find each paragraph's dealbreaker words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzfuysME0bq3"},"outputs":[],"source":["def find_specific_dealbreakers(input_keys, input_dictionary):\n","    my_dict = {\"new key\":[]}\n","    for i in range(len(list(input_dictionary.keys()))):\n","        for j in range(len(input_keys)):\n","            if input_keys[j] in list(input_dictionary.keys())[i]: \n","                my_dict[\"new key\"] += input_dictionary[list(input_dictionary.keys())[i]]\n","    return my_dict"]},{"cell_type":"markdown","metadata":{"id":"a2tErlSM0bq3"},"source":["First about dealbreaker words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2NZVyrZq0bq3"},"outputs":[],"source":["combined_check_list = []\n","\n","for j in range(len(paragraphs)):\n","    #check_list = []\n","\n","    new_dict = find_specific_dealbreakers(list(original_input_dictionary.values())[j], update_dealbreaker_words)\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","        # Iterate through the sensitive words grouped by category\n","        for category, words in new_dict.items():\n","            # Use regular expressions to search for the words in the sentence\n","            for word in words:\n","                matches = re.finditer(r'\\b'+word+r'\\b', sentence, re.IGNORECASE)\n","                for match in matches:\n","                    combined_check_list.append(match.group())\n","\n","\n","## combined_check_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8J_g6Pn60bq3","executionInfo":{"status":"ok","timestamp":1681190125077,"user_tz":240,"elapsed":76,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d4593a5-763e-4806-ced6-32ba81fc437d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['damages', 'remainder']"]},"metadata":{},"execution_count":78}],"source":["combined_check_list_syn = []\n","\n","for j in range(len(paragraphs)):\n","    new_dict = find_specific_dealbreakers(list(original_input_dictionary.values())[j], update_synonyms_dealbreaker_words)\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","        # Iterate through the sensitive words grouped by category\n","        for category, words in new_dict.items():\n","            # Use regular expressions to search for the words in the sentence\n","            for word in words:\n","                matches = re.finditer(r'\\b'+word+r'\\b', sentence, re.IGNORECASE)\n","                for match in matches:\n","                    combined_check_list_syn.append(match.group())\n","\n","## combined_check_list_syn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNTcB10y0bq4"},"outputs":[],"source":["# Clean it for unique words, Upper or lower case matters!\n","\n","combined_check_list = list(set(combined_check_list))\n","combined_check_list_syn = list(set(combined_check_list_syn))\n","\n","## combined_check_list\n","## combined_check_list_syn"]},{"cell_type":"markdown","metadata":{"id":"BvyiaSVF0bq4"},"source":["Then, about representative and rememdies. <br>\n","Here we need to find out whether they exist or not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExcMaNIi0bq4"},"outputs":[],"source":["# Representatives\n","representative_warning = True\n","\n","for j in range(len(original_input_dictionary)):\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","        \n","        for word in Representatives:\n","            \n","            if word in sentence:\n","                representative_warning = False\n","                ## print(f\"Found '{word}' in sentence: {sentence}\")\n","                break\n","        \n","        else:\n","            continue\n","\n","        break\n","    \n","\n","\n","##representative_warning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"op4vBBmB0bq4"},"outputs":[],"source":["# Remedies\n","remedies_warning = True\n","\n","for j in range(len(paragraphs)):\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","        \n","        for word in Remedies:\n","            if word in sentence:\n","                remedies_warning = False\n","                ## print(f\"Found '{word}' in sentence: {sentence}\")\n","                break\n","        else:\n","            continue\n","\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Bh3SLH70bq4"},"outputs":[],"source":["# Representatives Synonyms\n","syn_representative_warning = True\n","\n","for j in range(len(paragraphs)):\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","\n","        for word in unique_synonyms_representatives:\n","            if word in sentence:\n","                syn_representative_warning = False\n","                ## print(f\"Found '{word}' in sentence: {sentence}\")\n","                break\n","        else:\n","            continue\n","\n","        break\n","\n","\n","\n","if representative_warning == False:\n","    syn_representative_warning == False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2UIUMnm0bq4"},"outputs":[],"source":["# Synonyms Remedies\n","syn_remedies_warning = True\n","\n","for j in range(len(paragraphs)):\n","\n","    for i in range(len(sentences_in_paragraphs[j])):\n","        sentence = sentences_in_paragraphs[j][i]\n","\n","        for word in unique_synonyms_remedies:\n","            if word in sentence:\n","                syn_remedies_warning = False\n","                ## print(f\"Found '{word}' in sentence: {sentence}\")\n","                break\n","        else:\n","            continue\n","\n","        break\n","\n","\n","\n","if remedies_warning == False:\n","    syn_remedies_warning == False"]},{"cell_type":"markdown","metadata":{"id":"IZKPoUQ60bq4"},"source":["Export Stage"]},{"cell_type":"markdown","metadata":{"id":"G_LMEJIk0bq5"},"source":["Trial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOhQPko30bq5"},"outputs":[],"source":["##           ###           ##  EEEEEEEEEEEEEEEE      III\n"," ##         ## ##         ##   E                     III\n","  ##       ##   ##       ##    E                     III\n","   ##     ##     ##     ##     EEEEEEEEEEEEEEE       III\n","    ##   ##       ##   ##      E                     III\n","     ## ##         ## ##       E                     III\n","      ##            ##         EEEEEEEEEEEEEEEE      III"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8K_ugRR0bq5"},"outputs":[],"source":["# Import document again!\n","# 改这个地方你的输入路径哦 要docx，前面的 r 和中间\\\\不要动，重要\n","doc=docx.Document('/content/drive/MyDrive/Final_pipeline/NDA.docx')"]},{"cell_type":"code","source":["doc.paragraphs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s13i94tvTiAV","executionInfo":{"status":"ok","timestamp":1681190125081,"user_tz":240,"elapsed":60,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"3bce104f-b03c-4f07-a200-d940b3a72b64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<docx.text.paragraph.Paragraph at 0x7fdf37382fd0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382340>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf373828b0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf373824f0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382d90>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382fa0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf373823a0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382e50>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382cd0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382d00>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382b50>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf373823d0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37382310>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf373820a0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37258eb0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37258580>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37258d30>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4730>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4e20>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4640>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4fa0>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a40d0>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4ee0>,\n"," <docx.text.paragraph.Paragraph at 0x7fe03d1a4850>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2f10>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df24f0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df26a0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2dc0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2bb0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2970>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2400>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df20a0>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf36df2100>,\n"," <docx.text.paragraph.Paragraph at 0x7fdf37503850>]"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3qWW4ae0bq5"},"outputs":[],"source":["def find_key_by_value(value, dictionary):\n","    keys = []\n","    for key, val in dictionary.items():\n","        if isinstance(val, list):\n","            if any(v.lower() == value.lower() for v in val):\n","                keys.append(key)\n","        elif val.lower() == value.lower():\n","            keys.append(key)\n","    return keys if keys else None  # if value is not found in any key"]},{"cell_type":"markdown","metadata":{"id":"tjRgBF1o0bq5"},"source":["Giving comment on dealbreaker words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3Ufv0SK0bq5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681190125082,"user_tz":240,"elapsed":37,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"3b9412fe-c25b-41ac-8b08-f828bd6b2752"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","2\n"]}],"source":["def split_text(text, word):\n","    pattern = re.compile(r'([\\S\\s]*)(\\b{})([\\S\\s]*)'.format(word))\n","    match = pattern.search(text)\n","    if match:\n","        return match.groups()\n","    return None\n","\n","def split_Runs(doc,word):\n","    for p in doc.paragraphs:\n","        if p.text.find(word) != -1:\n","            virtualRuns=p.runs\n","            p.text = \"\"\n","            for r in virtualRuns:\n","                if r.text.find(word) != -1:\n","                    before, word, after = split_text(r.text, word)\n","                    p.add_run(before)\n","                    p.add_run()\n","                    p.add_run(word)\n","                    p.add_run(after)\n","                else:\n","                    p.add_run(r.text)\n","    return doc\n","\n","\n","\n","def style_Token2(doc,word,list1, dictionary1,dictionary2, comment=True):\n","    for p in doc.paragraphs:\n","        for i,r in enumerate(p.runs):\n","            if word in list1:\n","                if p.runs[i].text.find(word) != -1:\n","                    p.runs[i].font.highlight_color = WD_COLOR_INDEX.RED\n","                    if comment:\n","                        corresponded_key = find_key_by_value(word,dictionary1)\n","                        p.runs[i-1].add_comment(f'Wanring: \\\"{word}\\\" is classified as a category {corresponded_key} dealbreaker word.\\nStrongly Advice its Immediate Removal',author=\"DG1\")\n","                        print(1)\n","            else:\n","                if p.runs[i].text.find(word) != -1:\n","                    p.runs[i].font.highlight_color = WD_COLOR_INDEX.YELLOW\n","                    if comment:\n","                        corresponded_key = find_key_by_value(word,dictionary2)\n","                        p.runs[i-1].add_comment(f'Suggestion: \\\"{word}\\\" is a synonym of dealbreaker word belonging to category {corresponded_key}. We Recommend that you carefully evaluate its usage before considering its reintroduction.',author=\"DG1\")\n","                        print(2)\n","    return doc\n","\n","\n","\n","dealbreaker_and_syn_list = combined_check_list + combined_check_list_syn\n","dealbreaker_and_syn_list = list(set(dealbreaker_and_syn_list))\n","dealbreaker_and_syn_list\n","\n","for keyword in dealbreaker_and_syn_list:\n","    doc=split_Runs(doc,keyword)    \n","\n","for keyword in dealbreaker_and_syn_list:\n","    doc=style_Token2(doc,keyword,combined_check_list, dealbreaker_words, synonyms_dealbreaker_words,True)"]},{"cell_type":"markdown","metadata":{"id":"l1LBIu-_0bq5"},"source":["Giving Comment on Representative and Remedies <br>\n","if they exist, nothing will happen <br>\n","if they do not exist, output a warning comment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-eRKaM10bq5"},"outputs":[],"source":["def check_existence_for_remedy_representative(doc,warning_1 = True, warning_2 = True, warning_3 = True, warning_4 = True):\n","    if warning_1:\n","        paragraph1 = doc.add_paragraph()\n","        comment1 = paragraph1.add_comment(\"Warning: This document is lack of Representative Category information\", author = 'DG1')\n","    if warning_2:\n","        paragraph2 = doc.add_paragraph()\n","        comment2 = paragraph2.add_comment(\"Warning: This document is lack of Remedy Category information\",author = 'DG1')\n","    if warning_3:\n","        paragraph3 = doc.add_paragraph()\n","        comment3 = paragraph3.add_comment(\"Suggested Warning: This document is lack of synonyms of Representative Category information\", author = 'DG1')\n","    if warning_4:\n","        paragraph4 = doc.add_paragraph()\n","        comment4 = paragraph4.add_comment(\"Suggested Warning: This document is lack of synonyms of Remedy Category information\",author = 'DG1')\n","\n","\n","    return doc\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_bfjqty0bq6"},"outputs":[],"source":["doc = check_existence_for_remedy_representative(doc,representative_warning,remedies_warning,syn_representative_warning, syn_remedies_warning)"]},{"cell_type":"markdown","metadata":{"id":"y1Ma2JOW0bq6"},"source":["Output Path 输出路径"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYnJFYNL0bq6"},"outputs":[],"source":["##           ###           ##  EEEEEEEEEEEEEEEE             III\n"," ##         ## ##         ##   E                     III\n","  ##       ##   ##       ##    E                     III\n","   ##     ##     ##     ##     EEEEEEEEEEEEEEE              III\n","    ##   ##       ##   ##      E                     III\n","     ## ##         ## ##       E                     III\n","      ##           ##        EEEEEEEEEEEEEEEE             III"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIu1fa4O0bq6"},"outputs":[],"source":["# 这个地方要记得改哦， 还是别动r和docx还有\\\\\n","doc.save('/content/drive/MyDrive/Final_pipeline/NDA_db_syno_specialized.docx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0q4i5tZ0bq6"},"outputs":[],"source":["end_time = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikx-bVe30bq6"},"outputs":[],"source":["total_time = end_time - start_time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDo6yfp30bq6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681190125356,"user_tz":240,"elapsed":58,"user":{"displayName":"Yichen Li","userId":"05769548336440927322"}},"outputId":"3e6a5cb9-30a0-4b1a-fc78-f62688d4c03e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total time taken: 36.91 seconds\n"]}],"source":["print(f\"Total time taken: {total_time:.2f} seconds\")"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}